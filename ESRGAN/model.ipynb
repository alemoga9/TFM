{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"model.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyMsTsmhItpFdwWkD8RXYycM"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"GgkYF0JHjgn-"},"source":["# ESRGAN"]},{"cell_type":"code","metadata":{"id":"g6xisFCXjO3M"},"source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torchvision.models as models\n","from torch import Tensor\n","\n","\n","class ResidualDenseBlock(nn.Module):\n","    \"\"\"capas convolucionales densamente conectadas.\n","            channels (int): número de canales de la imagen de entrada.\n","            growths (int): número de canales que aumenta en cada capa de convolución.\n","    \"\"\"\n","\n","    def __init__(self, channels, growths):\n","        super(ResidualDenseBlock, self).__init__()\n","        self.conv1 = nn.Conv2d(channels + growths * 0, growths, (3, 3), (1, 1), (1, 1))\n","        self.conv2 = nn.Conv2d(channels + growths * 1, growths, (3, 3), (1, 1), (1, 1))\n","        self.conv3 = nn.Conv2d(channels + growths * 2, growths, (3, 3), (1, 1), (1, 1))\n","        self.conv4 = nn.Conv2d(channels + growths * 3, growths, (3, 3), (1, 1), (1, 1))\n","        self.conv5 = nn.Conv2d(channels + growths * 4, channels, (3, 3), (1, 1), (1, 1))\n","\n","        self.leaky_relu = nn.LeakyReLU(0.2, True)\n","        self.identity = nn.Identity()\n","\n","    def forward(self, x):\n","        out1 = self.leaky_relu(self.conv1(x))\n","        out2 = self.leaky_relu(self.conv2(torch.cat([x, out1], 1)))\n","        out3 = self.leaky_relu(self.conv3(torch.cat([x, out1, out2], 1)))\n","        out4 = self.leaky_relu(self.conv4(torch.cat([x, out1, out2, out3], 1)))\n","        out5 = self.identity(self.conv5(torch.cat([x, out1, out2, out3, out4], 1)))\n","        out = out5 * 0.2 + x\n","\n","        return out\n","\n","\n","class ResidualInResidualDenseBlock(nn.Module):\n","    \"\"\"Bloque de convolución densa residual multicapa.\n","    Args:\n","        channels (int): número de canales de la imagen de entrada.\n","        growths (int): número de canales que aumenta en cada capa de convolución.\n","    \"\"\"\n","\n","    def __init__(self, channels, growths):\n","        super(ResidualInResidualDenseBlock, self).__init__()\n","\n","        self.rdb1 = ResidualDenseBlock(channels, growths)\n","        self.rdb2 = ResidualDenseBlock(channels, growths)\n","        self.rdb3 = ResidualDenseBlock(channels, growths)\n","\n","    def forward(self, x):\n","        out = self.rdb1(x)\n","        out = self.rdb2(out)\n","        out = self.rdb3(out)\n","        out = out * 0.2 + x\n","\n","        return out\n","\n","\n","class Discriminator(nn.Module):\n","    def __init__(self):\n","        super(Discriminator, self).__init__()\n","        self.features = nn.Sequential(\n","            # input size. (3) x 256 x 256\n","            nn.Conv2d(3, 64, (3, 3), (1, 1), (1, 1), bias=True),\n","            nn.LeakyReLU(0.2, True),\n","\n","            # state size. (64) x 128 x 128\n","            nn.Conv2d(64, 64, (4, 4), (2, 2), (1, 1), bias=False),\n","            nn.BatchNorm2d(64),\n","            nn.LeakyReLU(0.2, True),\n","\n","            nn.Conv2d(64, 128, (3, 3), (1, 1), (1, 1), bias=False),\n","            nn.BatchNorm2d(128),\n","            nn.LeakyReLU(0.2, True),\n","\n","            # state size. (128) x 64 x 64\n","            nn.Conv2d(128, 128, (4, 4), (2, 2), (1, 1), bias=False),\n","            nn.BatchNorm2d(128),\n","            nn.LeakyReLU(0.2, True),\n","\n","            nn.Conv2d(128, 256, (3, 3), (1, 1), (1, 1), bias=False),\n","            nn.BatchNorm2d(256),\n","            nn.LeakyReLU(0.2, True),\n","\n","            # state size. (256) x 32 x 32\n","            nn.Conv2d(256, 256, (4, 4), (2, 2), (1, 1), bias=False),\n","            nn.BatchNorm2d(256),\n","            nn.LeakyReLU(0.2, True),\n","\n","            nn.Conv2d(256, 512, (3, 3), (1, 1), (1, 1), bias=False),\n","            nn.BatchNorm2d(512),\n","            nn.LeakyReLU(0.2, True),\n","\n","            # state size. (512) x 16 x 16\n","            nn.Conv2d(512, 512, (4, 4), (2, 2), (1, 1), bias=False),\n","            nn.BatchNorm2d(512),\n","            nn.LeakyReLU(0.2, True),\n","\n","            nn.Conv2d(512, 512, (3, 3), (1, 1), (1, 1), bias=False),\n","            nn.BatchNorm2d(512),\n","            nn.LeakyReLU(0.2, True),\n","\n","            # state size. (512) x 8 x 8\n","            nn.Conv2d(512, 512, (4, 4), (2, 2), (1, 1), bias=False),\n","            nn.BatchNorm2d(512),\n","            nn.LeakyReLU(0.2, True)\n","        )\n","\n","        self.classifier = nn.Sequential(\n","            nn.Linear(512 * 8 * 8, 100),\n","            nn.LeakyReLU(0.2, True),\n","            nn.Linear(100, 1),\n","        )\n","\n","    def forward(self, x):\n","        out = self.features(x)\n","        out = torch.flatten(out, 1)\n","        out = self.classifier(out)\n","\n","        return out\n","\n","\n","class Generator(nn.Module):\n","    def __init__(self):\n","        super(Generator, self).__init__()\n","\n","        # Primera capa convolucional\n","        self.conv_block1 = nn.Conv2d(3, 64, (3, 3), (1, 1), (1, 1))\n","\n","        # Red troncal de extracción de características\n","        trunk = []\n","        for _ in range(16):\n","            trunk += [ResidualInResidualDenseBlock(64, 32)]\n","        self.trunk = nn.Sequential(*trunk)\n","\n","        # Después de la red de extracción de características, reconecta una capa \n","        # de bloques convolucionales.\n","        self.conv_block2 = nn.Conv2d(64, 64, (3, 3), (1, 1), (1, 1))\n","\n","        # Capa convolucional de upsampling\n","        self.upsampling = nn.Sequential(\n","            nn.Conv2d(64, 64, (3, 3), (1, 1), (1, 1)),\n","            nn.LeakyReLU(0.2, True)\n","        )\n","\n","        # Reconecta un bloque de convolución tras la capa de upsampling\n","        self.conv_block3 = nn.Sequential(\n","            nn.Conv2d(64, 64, (3, 3), (1, 1), (1, 1)),\n","            nn.LeakyReLU(0.2, True)\n","        )\n","\n","        # Capa de salida\n","        self.conv_block4 = nn.Conv2d(64, 3, (3, 3), (1, 1), (1, 1))\n","\n","    \n","    def forward(self, x):\n","        out1 = self.conv_block1(x)\n","        out = self.trunk(out1)\n","        out2 = self.conv_block2(out)\n","        out = out1 + out2\n","        out = self.upsampling(F.interpolate(out, scale_factor=2, mode=\"nearest\"))\n","        out = self.upsampling(F.interpolate(out, scale_factor=2, mode=\"nearest\"))\n","        out = self.conv_block3(out)\n","        out = self.conv_block4(out)\n","\n","        return out\n","\n","    def _initialize_weights(self):\n","        for m in self.modules():\n","            if isinstance(m, nn.Conv2d):\n","                nn.init.kaiming_normal_(m.weight)\n","                if m.bias is not None:\n","                    nn.init.constant_(m.bias, 0)\n","                m.weight.data *= 0.1\n","            elif isinstance(m, nn.BatchNorm2d):\n","                nn.init.constant_(m.weight, 1)\n","                m.weight.data *= 0.1\n","\n","\n","class ContentLoss(nn.Module):\n","    \"\"\"Se construye una función de pérdida de contenido basada en la red VGG19.\n","       El uso de capas de mapeo de características de alto nivel de las últimas \n","       capas se centrará más en el contenido de textura de la imagen.\n","    \"\"\"\n","\n","    def __init__(self):\n","        super(ContentLoss, self).__init__()\n","\n","        # Se carga el modelo VGG19 entrenado en el dataset ImageNet.\n","        vgg19 = models.vgg19(pretrained=True, num_classes=1000).eval()\n","\n","        # Se extrae la salida de la capa 35 del modelo VGG19 como pérdida de contenido.\n","        self.feature_extractor = nn.Sequential(*list(vgg19.features.children())[:35])\n","\n","        # Se congelan los parámetros del modelo.\n","        for parameters in self.feature_extractor.parameters():\n","            parameters.requires_grad = False\n","\n","    def forward(self, sr, hr):\n","        # Pérdida basada en las diferencias de los mapas de características de \n","        # ambas imágenes.\n","        loss = F.l1_loss(self.feature_extractor(sr), self.feature_extractor(hr))\n","\n","        return loss"],"execution_count":null,"outputs":[]}]}