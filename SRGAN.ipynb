{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SRGAN.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "439d9f580ad6487ea930ea791da1a3f0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_c338a1fb59824f5e9225738dfb614695",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_803bab9bd00c438cb12752b13c6c3904",
              "IPY_MODEL_42c35af98012426e89ede30d1d216802",
              "IPY_MODEL_1d3b40730d194557a12a2687a0381278"
            ]
          }
        },
        "c338a1fb59824f5e9225738dfb614695": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "803bab9bd00c438cb12752b13c6c3904": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_e99c5e5a05124422b42ef02f57d4804b",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_16ed3c42ec4b432b84605655620ab6b8"
          }
        },
        "42c35af98012426e89ede30d1d216802": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_5c21f810ace7478f818995bd63ac74bd",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 574673361,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 574673361,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_6032b36747694f8a83be7883c3c1bc3f"
          }
        },
        "1d3b40730d194557a12a2687a0381278": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_4d2edb6db85a4c32bb9ed14fa364f27c",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 548M/548M [00:05&lt;00:00, 105MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_637283380f474799ab3ec9274e5b9b9b"
          }
        },
        "e99c5e5a05124422b42ef02f57d4804b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "16ed3c42ec4b432b84605655620ab6b8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "5c21f810ace7478f818995bd63ac74bd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "6032b36747694f8a83be7883c3c1bc3f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "4d2edb6db85a4c32bb9ed14fa364f27c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "637283380f474799ab3ec9274e5b9b9b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pFt-DC3cownF"
      },
      "source": [
        "# Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CZZjhM0aoYnp",
        "outputId": "369809b7-7086-4068-8cc0-6f0fa35652b3"
      },
      "source": [
        "# ¡¡¡ Conectar con Google Drive !!!\n",
        "\n",
        "# Se instala e importa import_ipynb para poder acceder a clases/funciones de otros notebooks\n",
        "!pip install -q import-ipynb\n",
        "\n",
        "# Se cambia al directorio donde esté el notebook con las clases a importar\n",
        "%cd \"/content/drive/MyDrive/Colab_Notebooks\"\n",
        "\n",
        "#!pip install --upgrade --force-reinstall --no-deps albumentations\n",
        "!pip install -q -U albumentations\n",
        "\n",
        "!pip install -q torchmetrics"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Building wheel for import-ipynb (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "/content/drive/MyDrive/Colab_Notebooks\n",
            "\u001b[K     |████████████████████████████████| 102 kB 37.9 MB/s \n",
            "\u001b[K     |████████████████████████████████| 37.1 MB 51 kB/s \n",
            "\u001b[K     |████████████████████████████████| 282 kB 37.3 MB/s \n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y9NQYnqwo0QV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3073dc26-0faf-4de3-e8f7-1a1d9e173af7"
      },
      "source": [
        "# Manejo y representación de datos\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os \n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Pytorch \n",
        "import torch\n",
        "from torch import Tensor\n",
        "from torch.autograd import Function\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.optim.lr_scheduler import StepLR\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "\n",
        "# Dataset y Dataloader\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torch.utils.data import Dataset , DataLoader\n",
        "\n",
        "# Transformaciones\n",
        "import albumentations as A\n",
        "from albumentations.pytorch import ToTensorV2\n",
        "from skimage.transform import resize\n",
        "\n",
        "# Modelos\n",
        "import import_ipynb\n",
        "from models import Generator, Discriminator, FeatureExtractor\n",
        "\n",
        "# Métricas\n",
        "from torchmetrics.functional import ssim\n",
        "from torchmetrics.functional import psnr\n",
        "from torchmetrics.functional import mean_squared_error as mse\n",
        "\n",
        "\n",
        "\n",
        "# Device\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "importing Jupyter notebook from models.ipynb\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3sHLM5p-pxM4"
      },
      "source": [
        "#Rutas y dataframe"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NJC4dewQpunX",
        "outputId": "738825fb-0fb3-43d0-f6c4-96ce5f891e74"
      },
      "source": [
        "img_fol= '/content/drive/MyDrive/Colab_Notebooks/carvana/train/' # Carpeta que contiene las imágenes\n",
        "\n",
        "# División en entrenamiento y validación\n",
        "df = pd.DataFrame(os.listdir(img_fol), columns = ['name'])       # Se estructura de forma tabular el contenido de la carpeta 'img_fol'\n",
        "df = df.iloc[:20]    # Se reduce el dataframe a 2000 imagenes\n",
        "df_train, df_val = train_test_split(df, test_size=.2, random_state=42, shuffle=True, stratify=None) \n",
        "\n",
        "# Tras realizar la división, es necesario reiniciar los índices\n",
        "df_train = df_train.reset_index()\n",
        "df_val = df_val.reset_index()\n",
        "\n",
        "print(f\"Total: {len(df)} -- Entrenamiento: {len(df_train)} -- Validación: {len(df_val)}\")\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total: 20 -- Entrenamiento: 16 -- Validación: 4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lEPs-pKlp4T9"
      },
      "source": [
        "#Dataset y dataloader"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rVm9B2Arp9Gb"
      },
      "source": [
        "class CarDataset(Dataset):\n",
        "    def __init__(self, df, transforms = None):\n",
        "        # self.df=pd.read_csv('/content/drive/MyDrive/Colab Notebooks/carvana/train_masks.csv')\n",
        "        self.df = df \n",
        "        self.transforms = transforms\n",
        "        self.img_fol= '/content/drive/MyDrive/Colab_Notebooks/carvana/train/'\n",
        "        self.mask_fol = '/content/drive/MyDrive/Colab_Notebooks/carvana/train_masks/' \n",
        "       \n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_name=self.df['name'][idx]\n",
        "        img_path=os.path.join(self.img_fol,img_name)    # Ruta completa imagen\n",
        "\n",
        "        img_HR = cv2.imread(img_path)      # Se carga la imagen\n",
        "        img_HR= cv2.cvtColor(img_HR, cv2.COLOR_BGR2RGB)\n",
        "        \n",
        "        if self.transforms:\n",
        "            img_HR = self.transforms(image=img_HR)['image']\n",
        "\n",
        "        # Factor de escala x4 en cada dimensión. Se mantiene el nº de canales\n",
        "        img_LR = resize(img_HR.numpy(), (3,img_HR.shape[1]//4,img_HR.shape[2]//4), anti_aliasing=True)\n",
        "        img_LR = torch.from_numpy(img_LR)\n",
        "        \n",
        "        # Se realiza una interpolación bicúbica para tener las mismas dimensiones que en la imagen original\n",
        "        # img_LR = cv2.resize(img_LR.transpose(1,2,0), (img_HR.shape[1],img_HR.shape[2]), interpolation = cv2.INTER_CUBIC).transpose(2,0,1)\n",
        "\n",
        "        # Se normaliza entre 0 y 1 para plotear  \n",
        "        img_HR = ((img_HR + img_HR.min().abs())/(img_HR + img_HR.min().abs()).max())\n",
        "        img_LR = ((img_LR + img_LR.min().abs())/(img_LR + img_LR.min().abs()).max())\n",
        "        \n",
        "        return img_HR, img_LR\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JYTdG2Ibp_K1"
      },
      "source": [
        "# Transformaciones\n",
        "transforms = A.Compose([\n",
        "            A.Resize(256, 256),\n",
        "            A.Normalize(mean=[0.485, 0.456, 0.406], \n",
        "                        std=[0.229, 0.224, 0.225]),\n",
        "            ToTensorV2()\n",
        "        ])\n",
        "\n",
        "# Datasets de entrenamiento y evaluación\n",
        "carDatasetTrain = CarDataset(df=df_train, transforms=transforms)\n",
        "carDatasetval = CarDataset(df=df_val, transforms=transforms)\n",
        "\n",
        "# Dataloaders de entrenamiento y evaluación\n",
        "train_dataloader = DataLoader(carDatasetTrain, batch_size=4,\n",
        "                        shuffle=True, num_workers=0)\n",
        "val_dataloader = DataLoader(carDatasetval, batch_size=4,\n",
        "                        shuffle=False, num_workers=0) # El dataloader de validación es fijo, no debe tener shuffle"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3SjXwhR36zrH"
      },
      "source": [
        "img_HR, img_LR = next(iter(train_dataloader))\n",
        "print(img_HR.shape, img_LR.shape)\n",
        "bs = img_HR.shape[0]\n",
        "plt.figure(figsize=(15,15))\n",
        "print(img_LR.shape)\n",
        "for i in range(bs):\n",
        "    plt.subplot(bs,2,(2*i+1))\n",
        "    plt.title(f\"Imagen con transformaciones\")\n",
        "    plt.imshow(img_HR[i].numpy().transpose(1,2,0))\n",
        "    plt.subplot(bs,2,(2*i+2))\n",
        "    plt.title(f\"Imagen submuestreada\")\n",
        "    plt.imshow(img_LR[i].numpy().transpose(1,2,0))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TEgNpVA1E-vV",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86,
          "referenced_widgets": [
            "439d9f580ad6487ea930ea791da1a3f0",
            "c338a1fb59824f5e9225738dfb614695",
            "803bab9bd00c438cb12752b13c6c3904",
            "42c35af98012426e89ede30d1d216802",
            "1d3b40730d194557a12a2687a0381278",
            "e99c5e5a05124422b42ef02f57d4804b",
            "16ed3c42ec4b432b84605655620ab6b8",
            "5c21f810ace7478f818995bd63ac74bd",
            "6032b36747694f8a83be7883c3c1bc3f",
            "4d2edb6db85a4c32bb9ed14fa364f27c",
            "637283380f474799ab3ec9274e5b9b9b"
          ]
        },
        "outputId": "59b5f836-25fc-46de-db1d-7cd7deda0d85"
      },
      "source": [
        "# Se instancian los modelos y se envían a la gpu si está disponible\n",
        "generator = Generator().to(device)                # Generador\n",
        "discriminator = Discriminator().to(device)        # Discriminador\n",
        "feature_extractor = FeatureExtractor().to(device) # \n",
        "\n",
        "# Si hay modelos guardados, se cargan\n",
        "if os.path.exists('/content/drive/MyDrive/Colab_Notebooks/saved_models/generator.pth'):\n",
        "    generator.load_state_dict(torch.load('/content/drive/MyDrive/Colab_Notebooks/saved_models/generator.pth')) # Se cargan los pesos del modelo\n",
        "\n",
        "if os.path.exists('/content/drive/MyDrive/Colab_Notebooks/saved_models/discriminator.pth'):\n",
        "    discriminator.load_state_dict(torch.load('/content/drive/MyDrive/Colab_Notebooks/saved_models/discriminator.pth')) # Se cargan los pesos del modelo\n",
        "\n",
        "\n",
        "# Funciones de pérdida\n",
        "pixel_criterion = torch.nn.MSELoss().to(device)\n",
        "content_criterion = torch.nn.MSELoss().to(device)\n",
        "adversarial_criterion = torch.nn.MSELoss().to(device)     # Adversarial loss.\n",
        "\n",
        "# Optimizers\n",
        "optimizer_G = torch.optim.Adam(generator.parameters(), lr=0.0002, betas=(0.5, 0.999))\n",
        "optimizer_D = torch.optim.Adam(discriminator.parameters(), lr=0.0002, betas=(0.5, 0.999))\n",
        "optimizer_P = torch.optim.Adam(generator.parameters(), lr=0.0002, betas=(0.9, 0.999))  \n",
        "\n",
        "cuda = torch.cuda.is_available()\n",
        "Tensor = torch.cuda.FloatTensor if cuda else torch.Tensor\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/vgg19-dcbb9e9d.pth\" to /root/.cache/torch/hub/checkpoints/vgg19-dcbb9e9d.pth\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "439d9f580ad6487ea930ea791da1a3f0",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "  0%|          | 0.00/548M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Kd5W3AnImvi"
      },
      "source": [
        "def train_generator(epoch, epochs, tloader):\n",
        "\n",
        "    # Se calcula el número de batches de entrenamiento\n",
        "    batches = len(train_dataloader)\n",
        "\n",
        "    # Se establece el generador en modo entrenamiento\n",
        "    generator.train()\n",
        "\n",
        "    for hr, lr in tloader:\n",
        "        # Los batches de imágenes se envían a la GPU si está disponible\n",
        "        lr, hr= lr.to(device), hr.to(device)\n",
        "\n",
        "        # Se ponen a cero los gradientes del generador\n",
        "        optimizer_G.zero_grad()\n",
        "\n",
        "        # Se obtiene la imagen SR\n",
        "        sr = generator(lr)\n",
        "\n",
        "        # Calculate the difference between the super-resolution image and the high-resolution image at the pixel level.\n",
        "        pixel_loss = pixel_criterion(sr, hr)\n",
        "\n",
        "        # Back propagation\n",
        "        pixel_loss.backward()\n",
        "\n",
        "        # Actualización de los pesos del generador\n",
        "        optimizer_P.step()\n",
        "\n",
        "\n",
        "def train_adversarial(epoch, epochs, tloader):\n",
        "    # Se calcula el número de batches de entrenamiento\n",
        "    batches = len(train_dataloader)\n",
        "\n",
        "    # Se establece la red adversarial en modo entrenamiento\n",
        "    discriminator.train()\n",
        "    generator.train()\n",
        "\n",
        "    for hr, lr in tloader:\n",
        "\n",
        "        # Los batches de imágenes se envían a la GPU si está disponible\n",
        "        lr, hr= lr.to(device), hr.to(device)\n",
        "\n",
        "        # Cantidad de imágenes que forman un batch\n",
        "        label_size = lr.size(0)\n",
        "\n",
        "        # Se crean las etiquetas. Se establecen en 1 para el caso real, y en 0 para el caso falso.\n",
        "        real_label = Tensor(np.ones((lr.size(0), *discriminator.output_shape)))\n",
        "        fake_label = Tensor(np.zeros((lr.size(0), *discriminator.output_shape)))\n",
        "\n",
        "        # Se ponen a cero los gradientes del discriminador\n",
        "        optimizer_D.zero_grad()\n",
        "\n",
        "        # Se calcula la pérdida del discriminador en la imagen HR.\n",
        "        output = discriminator(hr)\n",
        "        d_loss_hr = adversarial_criterion(output, real_label)\n",
        "        d_loss_hr.backward()\n",
        "        d_hr = output.mean().item()\n",
        "\n",
        "        # Se obtienen las imágenes SR\n",
        "        sr = generator(lr)\n",
        "\n",
        "        # Se calcula la pérdida del discriminador en la imagen SR.\n",
        "        output = discriminator(sr.detach())\n",
        "        d_loss_sr = adversarial_criterion(output, fake_label)\n",
        "        d_loss_sr.backward()\n",
        "        d_sr1 = output.mean().item()\n",
        "\n",
        "        # Actualización de los pesos del discriminador\n",
        "        d_loss = d_loss_hr + d_loss_sr\n",
        "        optimizer_D.step()\n",
        "\n",
        "        # Se ponen a cero los gradientes del generador\n",
        "        optimizer_G.zero_grad()\n",
        "\n",
        "        # Se calcula la pérdida del discriminador en la imagen SR\n",
        "        output = discriminator(sr)\n",
        "        \n",
        "        # Perceptual loss = 0.01 * pixel loss + 1.0 * content loss + 0.001 * adversarial loss.\n",
        "        pixel_loss = 0.01 * pixel_criterion(sr, hr.detach())\n",
        "\n",
        "        gen_features = feature_extractor(sr)\n",
        "        real_features = feature_extractor(hr)\n",
        "        content_loss = 1.0 * content_criterion(sr, hr.detach())\n",
        "\n",
        "        adversarial_loss = 0.001 * adversarial_criterion(output, real_label)\n",
        "\n",
        "        perceptual_loss = pixel_loss + content_loss + adversarial_loss\n",
        "\n",
        "        # Actualización de los pesos del generador\n",
        "        perceptual_loss.backward()\n",
        "        optimizer_G.step()\n",
        "        d_sr2 = output.mean().item()\n",
        "\n",
        "        #------------\n",
        "        # Métricas\n",
        "        #------------\n",
        "        \n",
        "        # Se calcula la PSNR\n",
        "        psnr_score = psnr(sr,hr)\n",
        "        epoch_psnr += psnr_score.item()      \n",
        "\n",
        "        # Se calcula el SSIM\n",
        "        ssim_score = ssim(sr, hr)\n",
        "        epoch_ssim += ssim_score.item()   \n",
        "\n",
        "        # Se calcula el RSME\n",
        "        rmse_score = mse(sr,hr,squared = True)\n",
        "        epoch_rmse += rmse_score.item() \n",
        "\n",
        "        tloader.set_postfix(loss_G=loss_G.item(),loss_D=loss_D.item(), psnr=psnr_score.item(), ssim=ssim_score.item(), rmse=rmse_score.item())\n",
        "\n",
        "\n",
        "    print(f'Train PSNR Epoch : {(epoch_psnr/n_train)}')\n",
        "    print(f'Train SSIM Epoch : {(epoch_ssim/n_train)}')\n",
        "    print(f'Train RMSE Epoch : {(epoch_rmse/n_train)}')\n",
        "\n",
        "    # Se devuelve el valor medio de cada métrica\n",
        "    return [(epoch_psnr/n_train),(epoch_ssim/n_train),(epoch_rmse/n_train)]\n",
        "\n",
        "\n",
        "def validate(vloader):\n",
        "    \n",
        "    vloader.set_description(f'Validation')\n",
        "\n",
        "    # Se calcula el número de batches de validación\n",
        "    batches = len(val_dataloader)\n",
        "\n",
        "    # Se establece el generador en modo evaluación\n",
        "    generator.eval()\n",
        "\n",
        "    # Se inicializan a 0 las variables que almacenarán las métricas   \n",
        "    # obtenidas en cada batch\n",
        "    epoch_psnr, epoch_ssim, epoch_rmse = 0,0,0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for index, (hr, lr) in enumerate(val_dataloader):\n",
        "\n",
        "            # Los batches de imágenes se envían a la GPU si está disponible\n",
        "            hr, lr = hr.to(device), lr.to(device)\n",
        "\n",
        "            # Se obtienen las imágenes SR\n",
        "            sr = generator(lr)\n",
        "\n",
        "            #------------\n",
        "            # Métricas\n",
        "            #------------\n",
        "\n",
        "            # Se calcula la PSNR\n",
        "            psnr_score = psnr(sr,hr)\n",
        "            epoch_psnr += psnr_score.item()      \n",
        "\n",
        "            # Se calcula el SSIM\n",
        "            ssim_score = ssim(sr, hr)\n",
        "            epoch_ssim += ssim_score.item()   \n",
        "\n",
        "            # Se calcula el RSME\n",
        "            rmse_score = mse(sr,hr,squared = True)\n",
        "            epoch_rmse += rmse_score.item()  \n",
        "\n",
        "            if index == 0:\n",
        "                  plt.figure(figsize=(15,15))\n",
        "                  plt.suptitle(f\"Epoch: {epoch+1}\\n\"\n",
        "                              +f\"SR:    RMSE: {rmse_score:.2f} -- PSNR: {psnr_score:.2f} -- SSIM: {ssim_score:.2f}\\n\",\n",
        "                              fontsize=16, y=0.96)\n",
        "                  for i in range(bs):\n",
        "                      plt.subplot(bs,3,(3*i+1))\n",
        "                      plt.title(f\"HR\")\n",
        "                      plt.imshow(hr[i].numpy().transpose(1,2,0))\n",
        "                      plt.subplot(bs,3,(3*i+2))\n",
        "                      plt.title(f\"LR\")\n",
        "                      plt.imshow(lr[i].numpy().transpose(1,2,0))\n",
        "                      plt.subplot(bs,3,(3*i+3))\n",
        "                      plt.title(f\"SR\")\n",
        "                      plt.imshow(sr[i].numpy().transpose(1,2,0))\n",
        "\n",
        "    print(f'Train PSNR Epoch : {(epoch_psnr/n_val)}')\n",
        "    print(f'Train SSIM Epoch : {(epoch_ssim/n_val)}')\n",
        "    print(f'Train RMSE Epoch : {(epoch_rmse/n_val)}')   \n",
        "    \n",
        "    # Se devuelve el valor medio de cada métrica\n",
        "    return [(epoch_psnr/batches),(epoch_ssim/batches),(epoch_rmse/batches)]\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wQFhLQxPP7uP",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "23164fd3-ec99-4d35-ca80-ed53cd7e0e3b"
      },
      "source": [
        "epochs = 5\n",
        "bs = 4\n",
        "# Se inicializan listas vacias en las que se almacenarán lás metricas de\n",
        "# entrenamiento para cada epoch \n",
        "train_psnr, train_ssim, train_rmse = [], [], []\n",
        "\n",
        "# Se inicializan listas vacias en las que se almacenarán lás metricas de\n",
        "# validación para cada epoch\n",
        "val_psnr, val_ssim, val_rmse = [], [], []\n",
        "\n",
        "# Entrenamiento generador\n",
        "\n",
        "\n",
        "# Entrenamiento adversarial\n",
        "\n",
        "for epoch in range(epochs) :\n",
        "\n",
        "    print(epoch+1,'/',epochs)\n",
        "\n",
        "    with tqdm(train_dataloader,unit='batch') as tloader : \n",
        "\n",
        "        train_generator(epoch,epochs,tloader)\n",
        "        train_scores = train_adversarial(epoch,epochs,tloader)\n",
        "\n",
        "        # Se almacenan las métricas en las listas correspondientes\n",
        "        train_psnr.append(train_scores[0])\n",
        "        train_ssim.append(train_scores[1])\n",
        "        train_rmse.append(train_scores[2])\n",
        "\n",
        "    with tqdm(val_dataloader,unit='batch') as vloader : \n",
        "        val_scores = validation(vloader)\n",
        "\n",
        "        # Se almacenan las métricas en las listas correspondientes\n",
        "        val_psnr.append(val_scores[0])\n",
        "        val_ssim.append(val_scores[1])\n",
        "        val_rmse.append(val_scores[2])\n",
        "\n",
        "        if epoch == 0:\n",
        "            best_psnr_value = 0  \n",
        "        is_best = val_ssim[epoch] > best_psnr_value\n",
        "        best_psnr_value = max(val_ssim[epoch], best_psnr_value)\n",
        "        if is_best:\n",
        "            torch.save(generator.state_dict(), \"/content/drive/MyDrive/Colab_Notebooks/saved_models/generator.pth\")\n",
        "            torch.save(discriminator.state_dict(), \"/content/drive/MyDrive/Colab_Notebooks/saved_models/discriminator.pth\")\n",
        "\n",
        "\n",
        "# Plots\n",
        "plt.subplot(1,3,1)\n",
        "plt.title(f\"RMSE\")\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('RMSE')\n",
        "plt.plot(train_rmse, label='train')\n",
        "plt.plot(val_rmse, label='validation')\n",
        "plt.legend()\n",
        "\n",
        "plt.subplot(1,3,2)\n",
        "plt.title(f\"PSNR\")\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('PSNR')\n",
        "plt.plot(train_psnr, label='train')\n",
        "plt.plot(val_psnr, label='validation')\n",
        "plt.legend()\n",
        "\n",
        "\n",
        "plt.subplot(1,3,3)\n",
        "plt.title(f\"SSIM\")\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('SSIM')\n",
        "plt.plot(train_ssim, label='train')\n",
        "plt.plot(val_ssim, label='validation')\n",
        "plt.legend()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1 / 5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/4 [00:00<?, ?batch/s]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-22-7bc4f3fb8fea>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0munit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'batch'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtloader\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0mtrain_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0;31m# Se almacenan las métricas en las listas correspondientes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'train' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7GkzAlumdUdb"
      },
      "source": [
        "plt.figure(figsize=(25,5))\n",
        "plt.subplot(1,5,1)\n",
        "plt.title(f\"Loss_G\")\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss_G')\n",
        "plt.plot(train_loss_G, label='train')\n",
        "plt.plot(val_loss_G, label='validation')\n",
        "plt.legend()\n",
        "\n",
        "plt.subplot(1,5,2)\n",
        "plt.title(f\"Loss_D\")\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss_D')\n",
        "plt.plot(train_loss_D, label='train')\n",
        "plt.plot(val_loss_G, label='validation')\n",
        "plt.legend()\n",
        "\n",
        "plt.subplot(1,5,3)\n",
        "plt.title(f\"RMSE\")\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('RMSE')\n",
        "plt.plot(train_rmse, label='train')\n",
        "plt.plot(val_rmse, label='validation')\n",
        "plt.legend()\n",
        "\n",
        "plt.subplot(1,5,4)\n",
        "plt.title(f\"PSNR\")\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('PSNR')\n",
        "plt.plot(train_psnr, label='train')\n",
        "plt.plot(val_psnr, label='validation')\n",
        "plt.legend()\n",
        "\n",
        "\n",
        "plt.subplot(1,5,5)\n",
        "plt.title(f\"SSIM\")\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('SSIM')\n",
        "plt.plot(train_ssim, label='train')\n",
        "plt.plot(val_ssim, label='validation')\n",
        "plt.legend()\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}